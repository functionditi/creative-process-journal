<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Creative Process Journal</title>
    <link rel="stylesheet" type="text/css" href="../style.css" />
</head>
<body class="page-body">

    <nav class="main__nav">
        <ul>
          <li><a href="./page12.html">previous</a></li>
          <li><a></a></li>
          <li><a href="./page14.html">next</a></li>
        </ul>
      </nav>

    <div class="grid-container" style="position: fixed;">
        <!-- <div class="title-name" style="grid-column: span 1;">
         
         </div> -->
         <div class="menu-list" style="grid-column: span 1;">

            <a href="../index.html"><h2>process + progress</h2></a>
            <!-- <br><br>
            <a onmouseover="revealImage('week1-image')" onmouseout="hideImage('week1-image')" href="./page1.html">
                <h4>←PREVIOUS</h4>
            </a>

            
            <a onmouseover="revealImage('week1-image')" onmouseout="hideImage('week1-image')" href="./page1.html">
                <h4>NEXT→</h4>
            </a> -->
           
         </div>
         <div style="grid-column: 6/ span 1; width: 80%">
            <h6>Week 3.</h6>
            <figcaption>12 August 2022 -<br> 19 August 2022</figcaption>
         </div>
    </div>
    <div class="grid-container">
        <div class="content" style="grid-column: 2/ span 4;" >
            
            
         
           
            <h3>
               
               SEN<span class="formula-alt">S</span>ING & SOL<span class="formula-alt">DE</span>RING
               <span class="formula-alt"></span>
               <span class="formula-alt"></span>

               
            </h3>  

            <br>
            
            <p>
                How can I tell what my plant is feeling? I don’t really know. Do plants even feel?

            </p>

            <figure>
                <img src="../assets/images/week-13/thermographic.png" alt="">
                <figcaption>Thermographic image data used to evaluate drought stress in maize plants. (Zubler and Yoon, 9)</figcaption>
            </figure>

            <p>
                I want to spend this week planning what my prototype will look like in accordance with the questions above. I came across this research article titled <a class="callout" href="https://pubmed.ncbi.nlm.nih.gov/33260412/" target="_blank">'Proximal Methods for Plant Stress Detection Using Optical Sensors and Machine Learning'</a>
                that looks into the detection of stress in plants through visual means. One means of detecting stress was through temperature, by capturing thermographic images of plants. I wondered if I could use a thermal imaging sensor to do the same, (obviously in a much lower-fidelity capacity).

            </p>

            <p>
                The same research article also looks into a variety of optical sensing methods to detect plant stress. All of their suggestions are in the context of agriculture and prioritise the production of food, however, but the application of it is still relevant here. 

            </p>
            <figure>
                <img src="../assets/images/week-13/optical-methods.png" alt="">
                <figcaption>Optical Methods Used for Plant Stress Detection (Zubler and Yoon, 11)</figcaption>
            </figure>

            <p>
                Looking at my MIRO board, I have three possible ways to begin to answer the question: How can I tell what my plant is feeling? 

            </p>
            <figure>
                <img src="../assets/images/week-13/miro-board.png" alt="">
             
            </figure>
            <br><br>

            <h5>AMG8833 Thermal Camera
            </h5>
            <br>
            <br>
            <figure>
                <img src="../assets/images/week-13/thermal-camera.avif" alt="">
                <figcaption><a class="callout" href="https://create.arduino.cc/projecthub/jdanielse/amg8833-thermal-camera-fc8478" target="_blank">Source</a></figcaption>
            </figure>

            <p>
                The thermal camera module required some prerequisite preparation which I did not do. Given the fact that we were two weeks away from prototype submission, I decided to shelf this experiment until I was able to get my hand on the sensor, maybe in India or maybe online in a few week’s time when it is shipped. Andreas suggested instead looking into IR sensors, or using actual camera modules instead.                 
            </p>

            <p>
                The aim was to use Individually Addressable LEDs to create light-based animations depending on plant stress, a way to indicate whether the plant was doing well or not.  
            </p>

            <h5>
                RGB Color Sensing
            </h5>

            <p>
                Dealing with the aspect of chlorophyll production = green = good health, I investigated using an RGB sensor to detect plant leaves. I bought a module from Sim Lim Tower and had to solder it together for it to work, which was my first time! 

            </p>
            <div style="display: grid; grid-template-columns: repeat(2, 1fr); column-gap: 1rem; ">
                <figure>
                    <img src="../assets/images/week-13/color-sensor-separate.jpg" alt="">
                   <figcaption>The RGB color sensor components.</figcaption>
                </figure>
                <figure>
                    <img src="../assets/images/week-13/unreliable-connections.jpg" alt="">
                    <figcaption>Connection was unstable when unsoldered.</figcaption>
                </figure>
            </div>
            <br>
            <div style="display: grid; grid-template-columns: repeat(2, 1fr); column-gap: 1rem; ">
                <figure>
                    <img src="../assets/images/week-13/soldering-badly.jpg" alt="">
                    <figcaption>Mistakenly using desoldering wire to solder, haha.</figcaption>
                </figure>
                <figure>
                    <video src="../assets/images/week-13/soldering-correctly.mp4" controls muted></video>
                    <figcaption>Finally got it right!</figcaption>
                </figure>
            </div>
            
            <p>
                I love soldering. It’s a very intricate process that you have to be quite careful with, but the satisfying hiss and fumes of the solder settling into place is great and relaxing (while casually holding a 400 degree celsius metal wand).            
            </p>

            <h5>
                Wearable Technology
            </h5>

            <p>
                I was thinking about how the above sensors could manifest in the form of a prototype. After reading a journal article about embodied interaction, I was wondering if thinking about wearable technology was a path worth wandering down. The benefits of wearable technology include portability, and ties back into the notions of ubiquitous computing quite well. 
            </p>

            <figure>
                <img src="../assets/images/week-13/basic-sketches.png" alt="">
                <figcaption>Some basic sketches ideating and wondering what a wearable artefact might look like.
                </figcaption>
            </figure>

            <p>
                When it comes to wearable tech, there are so many other factors to consider: how the artefact will sit on the hand, be put on, be removed, and how compact it can be. The Arduino is quite a bulky object, so how can it be condensed down into, say, a super convenient arm band that you can put on just like an Apple watch?
            </p>
            <p>
                In the case of a minimalistic approach, the first hand in the sketch above would be quite nice. Design considerations regarding aesthetics plays a huge role, but for the moment focusing on a grey-boxed, functional prototype would be adequate. 
            </p>

            <h5>
                Reflections
            </h5>

            <p>
                Some feedback I received from Andreas today was regarding how I explain my ideas/prototypes and experiments to others. Today I actually just brought a basic RGB colour sensing set up for our consultation, with little to no context, so something to keep in mind in the future is setting a scene and establishing a narrative before introducing developments to other people. 

            </p>

            <p>
                Some of my studio friends were also a bit confused as to why I was veering into wearable tech and did not seem entirely convinced by my reasoning of portability and ubiquitous computing. I think it was too drastic of a change in hindsight, and maybe I should think it through a little bit more and focus on its justification. Why am I doing it if I’m not sure?


            </p>

            <p>

Furthermore, I think I am veering into the territory of detecting plant stress a little too much, and losing the aspect of communication and interfaces which is my priority. By applying scientific evaluation methods, what new information can I possibly find that scientists haven’t done better? Maybe I should get back to and focus on the tangible interactions part. 

            </p>
           


           

            

        </div>

      
        
    </div>

</body>

    <script>
        
    </script>
</html>